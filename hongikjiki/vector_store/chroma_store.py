import os
import sys
import logging
from typing import List, Dict, Any, Optional, Union, Sequence, Tuple

import chromadb
from chromadb.config import Settings

from hongikjiki.vector_store.base import VectorStoreBase

logger = logging.getLogger("HongikJikiChatBot")

class ChromaVectorStore(VectorStoreBase):
    """
    ChromaDB ê¸°ë°˜ ë²¡í„° ì €ì¥ì†Œ êµ¬í˜„
    í…ìŠ¤íŠ¸ ì²­í¬ë¥¼ ë²¡í„°í™”í•˜ì—¬ ì €ì¥í•˜ê³  ìœ ì‚¬ë„ ê²€ìƒ‰ ê¸°ëŠ¥ ì œê³µ
    """
    
    def __init__(self, 
                collection_name: str = "hongikjiki_documents",
                persist_directory: str = "./data/vector_store",
                embeddings = None):
        """
        ChromaVectorStore ì´ˆê¸°í™”
        
        Args:
            collection_name: ì»¬ë ‰ì…˜ ì´ë¦„
            persist_directory: ë²¡í„° ì €ì¥ì†Œ ì§€ì†ì„± ë””ë ‰í† ë¦¬
            embeddings: ì„ë² ë”© ëª¨ë¸ (ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©)
        """
        super().__init__()
        
        # ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(persist_directory, exist_ok=True)
        
        # ì„ë² ë”© ì„¤ì •
        self.embeddings = embeddings
        
        # Chroma í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        self.client = chromadb.PersistentClient(
            path=persist_directory,
            settings=Settings(
                anonymized_telemetry=False,
                allow_reset=True
            )
        )
        
        # ì»¬ë ‰ì…˜ ìƒì„± ë˜ëŠ” ê°€ì ¸ì˜¤ê¸°
        self.collection = self.client.get_or_create_collection(
            name=collection_name,
            metadata={"hnsw:space": "cosine"}
        )
        
        # íƒœê·¸ ê´€ë ¨ í•„ë“œ ì´ˆê¸°í™”
        self.tag_index = None
        self.tag_aware_search = None
        
        # íƒœê·¸ ì¸ë±ìŠ¤ ë¡œë“œ ì‹œë„
        try:
            project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..'))
            if project_root not in sys.path:
                sys.path.append(project_root)
                
            from hongikjiki.vector_store.tag_index import TagIndex, TagAwareSearch
            
            # íƒœê·¸ ì¸ë±ìŠ¤ íŒŒì¼ í™•ì¸
            tag_index_path = os.path.join(project_root, 'data', 'tag_data', 'tag_index.json')
            if os.path.exists(tag_index_path):
                logger.info(f"íƒœê·¸ ì¸ë±ìŠ¤ ë¡œë“œ ì¤‘: {tag_index_path}")
                self.tag_index = TagIndex(tag_index_path)
                self.tag_aware_search = TagAwareSearch(self.tag_index)
                logger.info("íƒœê·¸ ê¸°ë°˜ ê²€ìƒ‰ ì´ˆê¸°í™” ì™„ë£Œ")
            else:
                logger.info(f"íƒœê·¸ ì¸ë±ìŠ¤ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {tag_index_path}")
        except ImportError:
            logger.info("íƒœê·¸ ëª¨ë“ˆì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì¼ë°˜ ê²€ìƒ‰ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        except Exception as e:
            logger.warning(f"íƒœê·¸ ì¸ë±ìŠ¤ ë¡œë“œ ì˜¤ë¥˜: {e}")
        
        logger.info(f"ChromaVectorStore ì´ˆê¸°í™” ì™„ë£Œ: ì»¬ë ‰ì…˜={collection_name}, ìœ„ì¹˜={persist_directory}")
    
    def add_texts(self, texts: List[str], metadatas: Optional[List[Dict[str, Any]]] = None) -> List[str]:
        """
        í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸ë¥¼ ë²¡í„° ì €ì¥ì†Œì— ì¶”ê°€
        
        Args:
            texts: ì¶”ê°€í•  í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸
            metadatas: ê° í…ìŠ¤íŠ¸ì— ëŒ€í•œ ë©”íƒ€ë°ì´í„° ë¦¬ìŠ¤íŠ¸ (ì˜µì…˜)
            
        Returns:
            List[str]: ì¶”ê°€ëœ ë¬¸ì„œ ID ë¦¬ìŠ¤íŠ¸
        """
        if not texts:
            logger.warning("ì¶”ê°€í•  í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return []
        
        if metadatas is None:
            metadatas = [{} for _ in texts]
        
        # ë©”íƒ€ë°ì´í„° ì •ë¦¬ (ë³µì¡í•œ íƒ€ì… ì²˜ë¦¬)
        sanitized_metadatas = []
        for metadata in metadatas:
            if metadata is None:
                sanitized_metadatas.append({})
                continue
                
            sanitized = {}
            for key, value in metadata.items():
                # None ê°’ ì²˜ë¦¬
                if value is None:
                    sanitized[key] = ""
                # ë¦¬ìŠ¤íŠ¸ ì²˜ë¦¬
                elif isinstance(value, list):
                    # ë¦¬ìŠ¤íŠ¸ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
                    sanitized[key] = ", ".join(str(item) for item in value) if value else ""
                # ë”•ì…”ë„ˆë¦¬ ì²˜ë¦¬
                elif isinstance(value, dict):
                    # ë”•ì…”ë„ˆë¦¬ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
                    sanitized[key] = str(value)
                # ê¸°ë³¸ íƒ€ì…ì€ ê·¸ëŒ€ë¡œ ì‚¬ìš©
                elif isinstance(value, (str, int, float, bool)):
                    sanitized[key] = value
                # ê·¸ ì™¸ íƒ€ì…ì€ ë¬¸ìì—´ë¡œ ë³€í™˜
                else:
                    sanitized[key] = str(value)
                    
            sanitized_metadatas.append(sanitized)
        
        # ë¬¸ì„œ ID ìƒì„±
        ids = [f"doc_{i}_{hash(text) % 10000000}" for i, text in enumerate(texts)]
        
        # ì„ë² ë”© ê³„ì‚°
        if self.embeddings:
            try:
                embeddings = self.embeddings.embed_documents(texts)
                # ë²¡í„° ì €ì¥ì†Œì— ì¶”ê°€
                self.collection.add(
                    ids=ids,
                    embeddings=embeddings,
                    documents=texts,
                    metadatas=sanitized_metadatas  # ì •ë¦¬ëœ ë©”íƒ€ë°ì´í„° ì‚¬ìš©
                )
            except Exception as e:
                logger.error(f"ë²¡í„° ì €ì¥ì†Œ ì¶”ê°€ ì˜¤ë¥˜: {e}")
                # ì˜¤ë¥˜ ìƒì„¸ ì¶œë ¥
                import traceback
                logger.error(traceback.format_exc())
                
                # ê°œë³„ ì•„ì´í…œ ì¶”ê°€ ì‹œë„
                successful_ids = []
                for i, (text, metadata) in enumerate(zip(texts, sanitized_metadatas)):
                    try:
                        text_embedding = self.embeddings.embed_documents([text])[0]
                        self.collection.add(
                            ids=[ids[i]],
                            embeddings=[text_embedding],
                            documents=[text],
                            metadatas=[metadata]
                        )
                        successful_ids.append(ids[i])
                        logger.info(f"ë‹¨ì¼ í•­ëª© ì¶”ê°€ ì„±ê³µ: {ids[i]}")
                    except Exception as item_error:
                        logger.error(f"ë‹¨ì¼ í•­ëª© ì¶”ê°€ ì‹¤íŒ¨ ({ids[i]}): {item_error}")
                
                return successful_ids
        else:
            # ì„ë² ë”© ê°ì²´ê°€ ì—†ëŠ” ê²½ìš° ë‚´ë¶€ ì„ë² ë”© ì‚¬ìš©
            try:
                self.collection.add(
                    ids=ids,
                    documents=texts,
                    metadatas=sanitized_metadatas  # ì •ë¦¬ëœ ë©”íƒ€ë°ì´í„° ì‚¬ìš©
                )
            except Exception as e:
                logger.error(f"ë²¡í„° ì €ì¥ì†Œ ì¶”ê°€ ì˜¤ë¥˜: {e}")
                # ì˜¤ë¥˜ ìƒì„¸ ì¶œë ¥
                import traceback
                logger.error(traceback.format_exc())
                
                # ê°œë³„ ì•„ì´í…œ ì¶”ê°€ ì‹œë„
                successful_ids = []
                for i, (text, metadata) in enumerate(zip(texts, sanitized_metadatas)):
                    try:
                        self.collection.add(
                            ids=[ids[i]],
                            documents=[text],
                            metadatas=[metadata]
                        )
                        successful_ids.append(ids[i])
                        logger.info(f"ë‹¨ì¼ í•­ëª© ì¶”ê°€ ì„±ê³µ: {ids[i]}")
                    except Exception as item_error:
                        logger.error(f"ë‹¨ì¼ í•­ëª© ì¶”ê°€ ì‹¤íŒ¨ ({ids[i]}): {item_error}")
                
                return successful_ids
        
        # íƒœê·¸ ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸ (íƒœê·¸ê°€ ìˆëŠ” ê²½ìš°)
        if self.tag_index:
            for i, metadata in enumerate(metadatas):
                if metadata and "tags" in metadata and metadata["tags"]:
                    doc_id = ids[i]
                    tags = metadata["tags"]
                    if isinstance(tags, str):
                        # ë¬¸ìì—´ì¸ ê²½ìš° ì‰¼í‘œë¡œ êµ¬ë¶„ëœ ê²ƒìœ¼ë¡œ ê°€ì •
                        tags = [tag.strip() for tag in tags.split(",")]
                    # íƒœê·¸ì˜ ì‹ ë¢°ë„ë¥¼ 1.0ìœ¼ë¡œ ì„¤ì •
                    tag_scores = {tag: 1.0 for tag in tags}
                    self.tag_index.add_document(doc_id, tag_scores)
            
            # ë³€ê²½ì‚¬í•­ ì €ì¥
            self.tag_index.save_index()
            logger.info(f"íƒœê·¸ ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸ ì™„ë£Œ: {len(ids)}ê°œ ë¬¸ì„œ")
        
        logger.info(f"{len(texts)}ê°œ í…ìŠ¤íŠ¸ ì¶”ê°€ ì™„ë£Œ")
        return ids
    
    def add_documents(self, documents: List[Dict[str, Any]]) -> List[str]:
        """
        ë¬¸ì„œ ê°ì²´ ë¦¬ìŠ¤íŠ¸ë¥¼ ë²¡í„° ì €ì¥ì†Œì— ì¶”ê°€
        
        Args:
            documents: ë¬¸ì„œ ê°ì²´ ë¦¬ìŠ¤íŠ¸ (content ë° metadata í•„ë“œ í¬í•¨)
            
        Returns:
            List[str]: ì¶”ê°€ëœ ë¬¸ì„œ ID ë¦¬ìŠ¤íŠ¸
        """
        texts = []
        metadatas = []
        
        for doc in documents:
            if "content" in doc:
                texts.append(doc["content"])
                metadatas.append(doc.get("metadata", {}))
            else:
                logger.warning(f"ë¬¸ì„œì— content í•„ë“œê°€ ì—†ìŠµë‹ˆë‹¤: {doc}")
        
        if not texts:
            logger.warning("ì¶”ê°€í•  í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return []
        
        return self.add_texts(texts, metadatas)
    
    def search(self, query: str, k: int = 5) -> List[Dict[str, Any]]:
        """
        ì¿¼ë¦¬ì— ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ë¬¸ì„œ ê²€ìƒ‰
        
        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            k: ë°˜í™˜í•  ê²°ê³¼ ìˆ˜
            
        Returns:
            List[Dict]: ê´€ë ¨ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸
        """
        try:
            logger.info(f"ë²¡í„° ê²€ìƒ‰ ì¿¼ë¦¬: '{query}' (k={k})")
            logger.info(f"ë²¡í„° ì €ì¥ì†Œ ë¬¸ì„œ ìˆ˜: {self.collection.count()}")
            
            # ì„ë² ë”© ê³„ì‚°
            if self.embeddings:
                query_embedding = self.embeddings.embed_query(query)
                logger.info(f"ì¿¼ë¦¬ ì„ë² ë”© ê³„ì‚° ì™„ë£Œ, ì°¨ì›: {len(query_embedding)}")
                
                # ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰
                results = self.collection.query(
                    query_embeddings=[query_embedding],
                    n_results=k,
                    include=["documents", "metadatas", "distances"]
                )
            else:
                # ì„ë² ë”© ê°ì²´ê°€ ì—†ëŠ” ê²½ìš° ë‚´ë¶€ ì„ë² ë”© ì‚¬ìš©
                logger.info("ë‚´ë¶€ ì„ë² ë”© ì‚¬ìš©")
                results = self.collection.query(
                    query_texts=[query],
                    n_results=k,
                    include=["documents", "metadatas", "distances"]
                )
            
            # ê²€ìƒ‰ ê²°ê³¼ê°€ ë¹„ì–´ìˆëŠ”ì§€ í™•ì¸
            if not results["ids"][0]:
                logger.warning("ê²€ìƒ‰ ê²°ê³¼ê°€ ë¹„ì—ˆìŠµë‹ˆë‹¤.")
                return []
            
            # ê²€ìƒ‰ ê²°ê³¼ ë³€í™˜
            documents = []
            for i in range(len(results["documents"][0])):
                score = 1.0 - float(results["distances"][0][i])  # ê±°ë¦¬ë¥¼ ìœ ì‚¬ë„ ì ìˆ˜ë¡œ ë³€í™˜
                documents.append({
                    "content": results["documents"][0][i],
                    "metadata": results["metadatas"][0][i],
                    "score": score
                })
                logger.info(f"ê²€ìƒ‰ ê²°ê³¼ {i+1}: ì ìˆ˜={score:.4f}, ë‚´ìš©={results['documents'][0][i][:50]}...")
            
            return documents
        except Exception as e:
            import traceback
            logger.error(f"ê²€ìƒ‰ ì˜¤ë¥˜: {e}\n{traceback.format_exc()}")
            return []
    
    def search_with_tags(self, query: str, tags: List[str] = None, 
                       tag_boost: float = 0.3, k: int = 4) -> List[Dict[str, Any]]:
        """
        íƒœê·¸ ê¸°ë°˜ìœ¼ë¡œ ê°•í™”ëœ ê²€ìƒ‰ ìˆ˜í–‰
        
        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            tags: ê²€ìƒ‰ì— ì‚¬ìš©í•  íƒœê·¸ ë¦¬ìŠ¤íŠ¸
            tag_boost: íƒœê·¸ ê°€ì¤‘ì¹˜ (0~1 ì‚¬ì´)
            k: ë°˜í™˜í•  ê²°ê³¼ ìˆ˜
            
        Returns:
            List[Dict]: ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        if not tags or not self.tag_aware_search:
            return self.search(query, k=k)
        
        logger.info(f"íƒœê·¸ ê¸°ë°˜ ê²€ìƒ‰: ì¿¼ë¦¬='{query}', íƒœê·¸={tags}, ê°€ì¤‘ì¹˜={tag_boost}")
        
        # ì¼ë°˜ ë²¡í„° ê²€ìƒ‰ (ë” ë§ì€ í›„ë³´ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°)
        candidates = self.search(query, k=k*2)
        
        if not candidates:
            logger.warning("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return []
        
        # íƒœê·¸ ê¸°ë°˜ ì¬ìˆœìœ„í™”
        reranked_results = self.tag_aware_search.rerank_results_by_tags(
            candidates, tags, tag_boost
        )
        
        # ìƒìœ„ kê°œ ê²°ê³¼ ë°˜í™˜
        return reranked_results[:k]
    
    def extract_query_tags(self, query: str) -> Tuple[str, List[str]]:
        """
        ì¿¼ë¦¬ì—ì„œ íƒœê·¸ ì°¸ì¡° ì¶”ì¶œ
        
        Args:
            query: ì‚¬ìš©ì ì¿¼ë¦¬
            
        Returns:
            Tuple[str, List[str]]: (ì •ë¦¬ëœ ì¿¼ë¦¬, ì¶”ì¶œëœ íƒœê·¸ ë¦¬ìŠ¤íŠ¸)
        """
        # íƒœê·¸ ì¸ì‹ ê²€ìƒ‰ì´ ì—†ìœ¼ë©´ ì›ë³¸ ì¿¼ë¦¬ ë°˜í™˜
        if not self.tag_aware_search:
            return query, []
        
        # íƒœê·¸ ìŠ¤í‚¤ë§ˆ ë¡œë“œ ì‹œë„
        try:
            project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..'))
            if project_root not in sys.path:
                sys.path.append(project_root)
                
            from hongikjiki.tagging.tag_schema import TagSchema
            
            # íƒœê·¸ ìŠ¤í‚¤ë§ˆ íŒŒì¼ í™•ì¸
            tag_schema_path = os.path.join(project_root, 'data', 'config', 'tag_schema.yaml')
            if os.path.exists(tag_schema_path):
                tag_schema = TagSchema(tag_schema_path)
                
                # ëª¨ë“  íƒœê·¸ ì´ë¦„ ê°€ì ¸ì˜¤ê¸°
                all_tags = [tag.name for tag in tag_schema.get_all_tags()]
                
                # íƒœê·¸ ì¶”ì¶œ
                clean_query, extracted_tags = self.tag_aware_search.extract_tags_from_query(query, all_tags)
                logger.info(f"ì¿¼ë¦¬ì—ì„œ íƒœê·¸ ì¶”ì¶œ: {extracted_tags}")
                
                return clean_query, extracted_tags
        except Exception as e:
            logger.warning(f"ì¿¼ë¦¬ì—ì„œ íƒœê·¸ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        
        return query, []
    
    def advanced_search(self, query: str, use_tags: bool = True, k: int = 4) -> List[Dict[str, Any]]:
        """
        íƒœê·¸ ì¶”ì¶œ ë° íƒœê·¸ ê¸°ë°˜ ê²€ìƒ‰ì„ í¬í•¨í•œ ê³ ê¸‰ ê²€ìƒ‰
        
        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            use_tags: íƒœê·¸ ê²€ìƒ‰ ì‚¬ìš© ì—¬ë¶€
            k: ë°˜í™˜í•  ê²°ê³¼ ìˆ˜
            
        Returns:
            List[Dict]: ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        if not use_tags or not self.tag_aware_search:
            return self.search(query, k=k)
        
        # ì¿¼ë¦¬ì—ì„œ íƒœê·¸ ì¶”ì¶œ
        clean_query, tags = self.extract_query_tags(query)
        
        # íƒœê·¸ê°€ ì—†ìœ¼ë©´ íƒœê·¸ ì¶”ì¶œ ì‹œë„
        if not tags:
            try:
                project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..'))
                if project_root not in sys.path:
                    sys.path.append(project_root)
                    
                from hongikjiki.tagging.tag_schema import TagSchema
                from hongikjiki.tagging.tag_extractor import TagExtractor
                
                # íƒœê·¸ ìŠ¤í‚¤ë§ˆ ë° íŒ¨í„´ íŒŒì¼ í™•ì¸
                tag_schema_path = os.path.join(project_root, 'data', 'config', 'tag_schema.yaml')
                tag_patterns_path = os.path.join(project_root, 'data', 'config', 'tag_patterns.json')
                
                if os.path.exists(tag_schema_path):
                    tag_schema = TagSchema(tag_schema_path)
                    tag_extractor = TagExtractor(
                        tag_schema, 
                        patterns_file=tag_patterns_path if os.path.exists(tag_patterns_path) else None
                    )
                    
                    # ì¿¼ë¦¬ ë‚´ìš©ì—ì„œ íƒœê·¸ ì¶”ì¶œ
                    tags = tag_extractor.extract_tags_from_query(clean_query)
            except Exception as e:
                logger.warning(f"ì¿¼ë¦¬ì—ì„œ íƒœê·¸ ì¶”ì¶œê¸° ì‚¬ìš© ì‹¤íŒ¨: {e}")
        
        # íƒœê·¸ ê¸°ë°˜ ê²€ìƒ‰ (íƒœê·¸ê°€ ìˆëŠ” ê²½ìš°)
        if tags:
            logger.info(f"ê³ ê¸‰ ê²€ìƒ‰ íƒœê·¸ ì‚¬ìš©: {tags}")
            return self.search_with_tags(clean_query, tags, k=k)
        else:
            return self.search(query, k=k)
    
    def count(self) -> int:
        """
        ë²¡í„° ì €ì¥ì†Œì˜ ë¬¸ì„œ ìˆ˜ ë°˜í™˜
        
        Returns:
            int: ì €ì¥ëœ ë¬¸ì„œ ìˆ˜
        """
        try:
            return self.collection.count()
        except Exception as e:
            logger.error(f"ë¬¸ì„œ ìˆ˜ ì¡°íšŒ ì˜¤ë¥˜: {e}")
            return 0
    
    def reset(self) -> None:
        """
        ë²¡í„° ì €ì¥ì†Œ ì´ˆê¸°í™”
        ëª¨ë“  ë¬¸ì„œë¥¼ ì‚­ì œí•˜ê³  ì €ì¥ì†Œë¥¼ ë¹„ì›€
        """
        try:
            self.client.reset()
            logger.warning("ë²¡í„° ì €ì¥ì†Œê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
            
            # íƒœê·¸ ì¸ë±ìŠ¤ë„ ì´ˆê¸°í™”
            if self.tag_index:
                # íƒœê·¸ ì¸ë±ìŠ¤ ë¦¬ì…‹ (ë¹ˆ ì¸ë±ìŠ¤ë¡œ ì €ì¥)
                self.tag_index = None
                from hongikjiki.vector_store.tag_index import TagIndex
                self.tag_index = TagIndex()
                self.tag_index.save_index()
                logger.warning("íƒœê·¸ ì¸ë±ìŠ¤ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            logger.error(f"ë²¡í„° ì €ì¥ì†Œ ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")
            raise
    
    def get_similar_documents(self, text: str, k: int = 5) -> List[Dict[str, Any]]:
        """
        ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ì™€ ìœ ì‚¬í•œ ë¬¸ì„œ ê²€ìƒ‰
        
        Args:
            text: ìœ ì‚¬ì„± ê²€ìƒ‰ì— ì‚¬ìš©í•  í…ìŠ¤íŠ¸
            k: ë°˜í™˜í•  ê²°ê³¼ ìˆ˜
            
        Returns:
            List[Dict]: ìœ ì‚¬í•œ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸
        """
        print("ğŸ§ª get_similar_documents() í˜¸ì¶œë¨")
        return self.search(text, k)
    
    def delete(self, document_ids: List[str]) -> None:
        """
        ë²¡í„° ì €ì¥ì†Œì—ì„œ ë¬¸ì„œ ì‚­ì œ
        
        Args:
            document_ids: ì‚­ì œí•  ë¬¸ì„œ ID ë¦¬ìŠ¤íŠ¸
        """
        try:
            self.collection.delete(ids=document_ids)
            logger.info(f"{len(document_ids)}ê°œ ë¬¸ì„œ ì‚­ì œ ì™„ë£Œ")
            
            # íƒœê·¸ ì¸ë±ìŠ¤ì—ì„œë„ ì‚­ì œ
            if self.tag_index:
                for doc_id in document_ids:
                    self.tag_index.remove_document(doc_id)
                self.tag_index.save_index()
                logger.info(f"íƒœê·¸ ì¸ë±ìŠ¤ì—ì„œ {len(document_ids)}ê°œ ë¬¸ì„œ ì‚­ì œ ì™„ë£Œ")
        except Exception as e:
            logger.error(f"ë¬¸ì„œ ì‚­ì œ ì˜¤ë¥˜: {e}")
            raise