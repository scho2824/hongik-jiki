

import json
import os
from langchain.schema import Document
from hongikjiki.vector_store.chroma_store import ChromaVectorStore
from hongikjiki.vector_store.embeddings import get_embeddings

def load_qa_pairs(file_path):
    with open(file_path, "r", encoding="utf-8") as f:
        return json.load(f)

def convert_to_documents(qa_pairs):
    documents = []
    for pair in qa_pairs:
        content = f"Q: {pair['question']}\nA: {pair['answer']}"
        documents.append(Document(page_content=content, metadata={"source": "jungbub_qa"}))
    return documents

def build_vector_store(qa_file, persist_dir="./data/vector_store", collection_name="hongikjiki_jungbub"):
    print("ğŸ”¹ QA ë°ì´í„° ë¡œë“œ ì¤‘...")
    qa_pairs = load_qa_pairs(qa_file)
    print(f"ğŸ”¹ ì´ {len(qa_pairs)}ê°œì˜ QA í•­ëª©")

    docs = convert_to_documents(qa_pairs)

    print("ğŸ”¹ ë²¡í„° ì €ì¥ì†Œ ì´ˆê¸°í™” ì¤‘...")
    vector_store = ChromaVectorStore(
        collection_name=collection_name,
        persist_directory=persist_dir,
        embeddings=get_embeddings("openai", model="text-embedding-3-small")
    )

    print("ğŸ”¹ ë¬¸ì„œ ì„ë² ë”© ë° ì €ì¥ ì¤‘...")
    vector_store.add_texts([doc.page_content for doc in docs], metadatas=[doc.metadata for doc in docs])
    vector_store.persist()
    print("âœ… ë²¡í„° ì €ì¥ì†Œ êµ¬ì¶• ì™„ë£Œ!")

if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument("--qa_file", type=str, required=True, help="Path to QA JSON file")
    args = parser.parse_args()

    build_vector_store(args.qa_file)